{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DeaDom/imersao_ia/blob/main/Imers%C3%A3o_IA_Aula_04.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "nFQLKQ6hfXch"
      },
      "outputs": [],
      "source": [
        "#Instalando o SDK do Google\n",
        "!pip install -q -U google-generativeai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "IthzwfnAfcsi"
      },
      "outputs": [],
      "source": [
        "#Configurações iniciais\n",
        "import google.generativeai as genai\n",
        "\n",
        "GOOGLE_API_KEY=\"INSIRA_SUA_API_KEY\"\n",
        "from google.colab import userdata\n",
        "api_key = userdata.get (\"SECRET_KEY\")\n",
        "genai.configure(api_key=api_key)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138
        },
        "id": "iD3ihugymWBt",
        "outputId": "34ce806d-dab3-4308-ff8c-b5c6ee17ca25"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "models/gemini-1.0-pro\n",
            "models/gemini-1.0-pro-001\n",
            "models/gemini-1.0-pro-latest\n",
            "models/gemini-1.0-pro-vision-latest\n",
            "models/gemini-1.5-pro-latest\n",
            "models/gemini-pro\n",
            "models/gemini-pro-vision\n"
          ]
        }
      ],
      "source": [
        "#Listando os modelos disponíveis\n",
        "for m in genai.list_models():\n",
        "  if 'generateContent' in m.supported_generation_methods:\n",
        "    print(m.name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "O1ochaeyDn_o"
      },
      "outputs": [],
      "source": [
        "generation_config = {\n",
        "  \"candidate_count\": 1,\n",
        "  \"temperature\": 0.5,\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "jwBv7DofDofw"
      },
      "outputs": [],
      "source": [
        "safety_settings={\n",
        "    'HATE': 'BLOCK_NONE',\n",
        "    'HARASSMENT': 'BLOCK_NONE',\n",
        "    'SEXUAL' : 'BLOCK_NONE',\n",
        "    'DANGEROUS' : 'BLOCK_NONE'\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "NIiSs1R5mVJE"
      },
      "outputs": [],
      "source": [
        "model = genai.GenerativeModel(model_name='gemini-1.0-pro',\n",
        "                                  generation_config=generation_config,\n",
        "                                  safety_settings=safety_settings,)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "vrRjhT2rlrU_",
        "outputId": "5ac65080-9b17-471f-ab47-8c99949c3c3e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Google'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "response = model.generate_content(\"Que empresa criou o modelo de IA Gemini?\")\n",
        "response.text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 590
        },
        "id": "KpaQ6hm5f2_J",
        "outputId": "5a576f7d-ca19-4496-d9e0-f21bb597412c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Esperando prompt: REALIZE UM PARABÉNS\n",
            "Resposta: **Parabéns, parabéns, parabéns!**\n",
            "\n",
            "Hoje é um dia muito especial,\n",
            "Pois é o seu aniversário, é o seu natal.\n",
            "Que você possa aproveitar cada momento,\n",
            "Com muita alegria e contentamento.\n",
            "\n",
            "Que seus sonhos se realizem um a um,\n",
            "E que você seja sempre muito feliz.\n",
            "Que o amor e a paz estejam sempre com você,\n",
            "E que você tenha muitos anos de vida para viver.\n",
            "\n",
            "Parabéns, parabéns, parabéns!\n",
            "Que este dia seja repleto de surpresas e emoções.\n",
            "Que você possa celebrar ao lado das pessoas que ama,\n",
            "E que você possa guardar este dia para sempre na memória.\n",
            "\n",
            "Parabéns, parabéns, parabéns!\n",
            "Que você tenha um ano maravilhoso, cheio de realizações e conquistas.\n",
            "Que você possa continuar sendo essa pessoa incrível que você é,\n",
            "E que você possa sempre inspirar aqueles que estão ao seu redor.\n",
            "\n",
            "Parabéns, parabéns, parabéns! \n",
            "\n",
            "\n",
            "Esperando prompt: FIM\n",
            "Resposta: **FIM**\n",
            "\n",
            "Que este seja apenas o começo de um novo capítulo incrível em sua vida. Parabéns mais uma vez! \n",
            "\n",
            "\n",
            "Esperando prompt: fim\n"
          ]
        }
      ],
      "source": [
        "chat = model.start_chat(history=[])\n",
        "\n",
        "prompt = input('Esperando prompt: ')\n",
        "\n",
        "while prompt != \"fim\":\n",
        "  response = chat.send_message(prompt)\n",
        "  print(\"Resposta:\", response.text, '\\n\\n')\n",
        "  prompt = input('Esperando prompt: ')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XLAniTTDhHNW"
      },
      "outputs": [],
      "source": [
        "chat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sd8mvW9KghTf"
      },
      "outputs": [],
      "source": [
        "chat.history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dAcbPBocgzeX"
      },
      "outputs": [],
      "source": [
        "#Melhorando a visualização\n",
        "#Código disponível em https://ai.google.dev/tutorials/python_quickstart#import_packages\n",
        "import textwrap\n",
        "from IPython.display import display\n",
        "from IPython.display import Markdown\n",
        "\n",
        "def to_markdown(text):\n",
        "  text = text.replace('•', '  *')\n",
        "  return Markdown(textwrap.indent(text, '> ', predicate=lambda _: True))\n",
        "\n",
        "#Imprimindo o histórico\n",
        "for message in chat.history:\n",
        "  display(to_markdown(f'**{message.role}**: {message.parts[0].text}'))\n",
        "  print('-------------------------------------------')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}